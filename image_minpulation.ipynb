{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image minpulation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGuw4bqikJZP"
      },
      "source": [
        "#Import Libraries\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf2BTX3akS9s"
      },
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1000\n",
        "args['test_batch_size']=2\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=False\n"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fCwYTdUkcwO"
      },
      "source": [
        "#load the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "764DZHUNZ_nH"
      },
      "source": [
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UruNqAvEaE3Y"
      },
      "source": [
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n",
        "def test():\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_loss = 0\n",
        "      correct = 0\n",
        "      for data, target in test_loader:\n",
        "          if args['cuda']:\n",
        "              data, target = data.cuda(), target.cuda()\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          print(len(data), \"Itmes\")\n",
        "          output = model(data)\n",
        "          test_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
        "          pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "          correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "      test_loss /= len(test_loader.dataset)\n",
        "      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          test_loss, correct, len(test_loader.dataset),\n",
        "          100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "\n",
        "def testMultilabel():\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      newcorrect = 0\n",
        "\n",
        "      for data, target in test_loader:\n",
        "          oldtarget = target\n",
        "          target = F.one_hot(target, num_classes=10)\n",
        "          newdata = torch.zeros_like(data)[0:8]\n",
        "          newtarget = torch.zeros_like(target, dtype=torch.float64)[0:8]\n",
        "          \n",
        "          for i in range(0, len(data), 2):\n",
        "            x1 = data[i]\n",
        "            x2 = data[i+1]\n",
        "            y1 = target[i]\n",
        "            y2 = target[i+1]\n",
        "            x,y = concatImages(x1,x2,y1,y2)\n",
        "            newdata[i//2] = x\n",
        "            newtarget[i//2] = y\n",
        "\n",
        "\n",
        "\n",
        "          # print(\"**********************INPUT: \")\n",
        "          # print(\"Normal:\")\n",
        "          # printImageWithLabel(x1.numpy()[0], y1)\n",
        "          # printImageWithLabel(x2.numpy()[0], y2)\n",
        "          # print(\"MultiLabel: \")\n",
        "          # printImageWithLabel(x.numpy()[0], y)\n",
        "          output = model(data)\n",
        "          newoutput = model(newdata)\n",
        "\n",
        "\n",
        "          if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            data, target = Variable(data), Variable(target)\n",
        "            newdata, newtarget = newdata.cuda(), newtarget.cuda()\n",
        "            newdata, newtarget = Variable(newdata), Variable(newtarget)\n",
        "\n",
        "          pred = output.data.max(1, keepdim=True)[1]\n",
        "          correct += pred.eq(oldtarget.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "          \n",
        "          answers = torch.argsort(newtarget, dim=1, descending=True).numpy()\n",
        "          newpred = torch.argsort(newoutput, dim=1, descending=True).numpy()\n",
        "          \n",
        "\n",
        "          for i in range(0, len(data), 2):\n",
        "            # print(\"preds     target       matches\")\n",
        "            # print(newpred[i//2][:2], \"          \", answers[i//2][:2], \"     \", compareArrays(answers[i//2][:2],newpred[i//2][:2]))\n",
        "            newcorrect += compareArrays(answers[i//2][:2],newpred[i//2][:2])\n",
        "          # correct += pred.eq(answers).long().cpu().sum()\n",
        "          \n",
        "          # for i in range(len(data)):\n",
        "          #   print(\"Unipreds     Unitarget\")\n",
        "          #   print(pred[i].item(), \"          \",oldtarget[i].item())\n",
        "          # sleep(0)\n",
        "          \n",
        "          if correct % 1000 == 0 :\n",
        "            print (correct)\n",
        "\n",
        "          # correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "      \n",
        "      print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          correct, len(test_loader.dataset),\n",
        "          100. * correct / len(test_loader.dataset)))\n",
        "      print('\\nTest set: New Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          newcorrect, len(test_loader.dataset),\n",
        "          100. * newcorrect / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SlGoXb8aJds"
      },
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWb36J8iovZE",
        "outputId": "c0ef62d1-7989-48f8-8b4d-4c710b80ca3a"
      },
      "source": [
        "testMultilabel()"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2000)\n",
            "tensor(3000)\n",
            "tensor(4000)\n",
            "tensor(6000)\n",
            "tensor(7000)\n",
            "tensor(9000)\n",
            "\n",
            "Test set: Accuracy: 9299/10000 (93%)\n",
            "\n",
            "\n",
            "Test set: New Accuracy: 2743/10000 (27%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gDU1DGcltRh"
      },
      "source": [
        "def concatImages(imageOne, imageTwo, labelOne, labelTwo, concatnitionAxis=2):\n",
        "  x = torch.cat((imageOne, imageTwo), dim=concatnitionAxis)\n",
        "  y = (labelOne+ labelTwo)/2\n",
        "\n",
        "  temp = torch.from_numpy(cv2.resize(x.numpy()[0], (28, 28)) )\n",
        "  x = torch.zeros_like(x1)\n",
        "  x[0] = temp\n",
        "  return x,y"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DBt4NT2CyV_"
      },
      "source": [
        "def printImageWithLabel(image, label):\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.show()\n",
        "  print(\"Lable\", label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Hwz5xS88W7"
      },
      "source": [
        "def compareArrays (a,b):\n",
        "  matches = 0\n",
        "  for i in range(len(a)):\n",
        "    if a[i] in b :\n",
        "      matches += 1\n",
        "  return matches"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgIhvE9Jg-DU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}